{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hamest import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, TerminateOnNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_over = 1000\n",
    "batches_worth_of_data = 1\n",
    "batch_size = 512\n",
    "max_epochs = 50\n",
    "steps_per_epoch = batches_worth_of_data*2\n",
    "\n",
    "model_checkpoint_filepath = 'm_checkpoint'\n",
    "model1_checkpoint_filepath = 'm1_checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_hists = lambda h: {k:(sum((_.get(k,[None]) for _ in h),[])) for k in h[-1].keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model dependent stuff\n",
    "\n",
    "This is the source of training data. It is implemented in a separate module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ringham import *\n",
    "\n",
    "n = 3\n",
    "SPAM = 0.0\n",
    "\n",
    "nb_drives = qubitring_ndrives(n)\n",
    "hs = np.stack([_.full() for _ in qubitring_all_ops(n)])\n",
    "\n",
    "_epsilons = [0.1]*n\n",
    "_etas = [0.01]*n\n",
    "_deltas = [2.]*qubitring_ndrives(n)\n",
    "jitter = 0.05\n",
    "s = np.random.RandomState(seed=36)\n",
    "_epsilons *= s.normal(loc=1., scale=jitter, size=n)\n",
    "_etas     *= s.normal(loc=1., scale=jitter, size=n)\n",
    "_deltas   *= s.normal(loc=1., scale=jitter, size=qubitring_ndrives(n))\n",
    "\n",
    "H0 = qubitring_H0(n, _epsilons, _etas).full()\n",
    "Hdrives = np.stack([_.full() for _ in qubitring_Hdrives(n, _deltas)])\n",
    "\n",
    "val_seed = 1\n",
    "train_seed = 42\n",
    "validation_data = next(qubitring_datagen(H0, Hdrives, n=n, batch_size=512, Delta=1., seed=val_seed, average_over=float('inf')))\n",
    "\n",
    "gen_train = qubitring_datagen(H0, Hdrives, n=n, batch_size=512, Delta=1.,\n",
    "                              seed=train_seed, average_over=average_over, step_reset=batches_worth_of_data,\n",
    "                              spam=SPAM)\n",
    "data_est_std = next(qubitring_datagen(H0, Hdrives, n=n, batch_size=512, Delta=1.,\n",
    "                                      seed=train_seed, average_over=average_over,\n",
    "                                      spam=SPAM))\n",
    "# data_est_std is a \"copy\" of the first batch of gen_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter estimation\n",
    "\n",
    "- start with Low Parameterization where you specify the permitted Hamiltonian components;\n",
    "- then move to High Parameterization (with linear drives), seeding it with the previous results;\n",
    "- if necessary permit non-linear drives [not a default implementation];\n",
    "- either one of the previous three models can be embedded in a time-dependent unitary model:\n",
    "    - the unitary time-dependent model permits advanced integration methods (not just Euler), hence you need fewer timesteps (you have better scaling);\n",
    "- you cal also move to non-unitary time-dependent models:\n",
    "    - you have to specify the Lindblad operators;\n",
    "    - only naive integration (Euler) is available, so you will need more timesteps.\n",
    "- either one of the time-dependent models can be used in reverse in order to train a control pulse for a target state preparation or a target unitary [not a default implementation]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(StateProbabilitiesPaulied(nqubits=n, ndrives=nb_drives, paulies=hs,\n",
    "                                    l1_lambda=2e-3))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=1e-3), metrics=['mse', 'mae', 'binary_crossentropy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best: 0.013242281338272318\n"
     ]
    }
   ],
   "source": [
    "guess_size = 10\n",
    "guess_distance = 0.1\n",
    "gen_guess = qubitring_datagen(H0, Hdrives, n=n, batch_size=512, Delta=1.,\n",
    "                              seed=train_seed, average_over=average_over, step_reset=1)\n",
    "noise = 0.30\n",
    "_epsilons_false = np.random.normal(loc=1., scale=noise, size=n)*_epsilons\n",
    "_etas_false     = np.random.normal(loc=1., scale=noise, size=n)*_etas\n",
    "_deltas_false   = np.random.normal(loc=1., scale=noise, size=qubitring_ndrives(n))*_deltas\n",
    "guess_w_b = lambda : qubitring_perfect_pauli_weights(n, _epsilons_false, _etas_false, _deltas_false, noise=guess_distance)\n",
    "\n",
    "starts = []\n",
    "best = float('inf')\n",
    "for i in range(guess_size):\n",
    "    print('\\rbest:',best, end='', flush=True)\n",
    "    w, b = guess_w_b()\n",
    "    model.set_weights([w, b])\n",
    "    start = model.fit_generator(gen_guess, verbose=0, steps_per_epoch=1, epochs=1, callbacks=[]).history\n",
    "    starts.append(start)\n",
    "    if start['mean_squared_error'][-1] < best:\n",
    "        best = start['mean_squared_error'][-1]\n",
    "        best_start = start\n",
    "        best_ws = [w, b]\n",
    "print()\n",
    "model.set_weights(best_ws)\n",
    "hists.append(best_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 0.0139 - mean_squared_error: 0.0132 - mean_absolute_error: 0.0727 - binary_crossentropy: 0.3530 - val_loss: 0.0147 - val_mean_squared_error: 0.0140 - val_mean_absolute_error: 0.0738 - val_binary_crossentropy: 0.3502\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.0138 - mean_squared_error: 0.0131 - mean_absolute_error: 0.0724 - binary_crossentropy: 0.3527 - val_loss: 0.0146 - val_mean_squared_error: 0.0139 - val_mean_absolute_error: 0.0737 - val_binary_crossentropy: 0.3500\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.0136 - mean_squared_error: 0.0130 - mean_absolute_error: 0.0721 - binary_crossentropy: 0.3524 - val_loss: 0.0145 - val_mean_squared_error: 0.0139 - val_mean_absolute_error: 0.0736 - val_binary_crossentropy: 0.3498\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.0135 - mean_squared_error: 0.0128 - mean_absolute_error: 0.0718 - binary_crossentropy: 0.3521 - val_loss: 0.0145 - val_mean_squared_error: 0.0138 - val_mean_absolute_error: 0.0735 - val_binary_crossentropy: 0.3496\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0134 - mean_squared_error: 0.0127 - mean_absolute_error: 0.0715 - binary_crossentropy: 0.3517 - val_loss: 0.0144 - val_mean_squared_error: 0.0138 - val_mean_absolute_error: 0.0734 - val_binary_crossentropy: 0.3495\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0132 - mean_squared_error: 0.0126 - mean_absolute_error: 0.0711 - binary_crossentropy: 0.3511 - val_loss: 0.0144 - val_mean_squared_error: 0.0137 - val_mean_absolute_error: 0.0732 - val_binary_crossentropy: 0.3494\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.0131 - mean_squared_error: 0.0124 - mean_absolute_error: 0.0708 - binary_crossentropy: 0.3507 - val_loss: 0.0143 - val_mean_squared_error: 0.0137 - val_mean_absolute_error: 0.0731 - val_binary_crossentropy: 0.3493\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0129 - mean_squared_error: 0.0123 - mean_absolute_error: 0.0705 - binary_crossentropy: 0.3503 - val_loss: 0.0142 - val_mean_squared_error: 0.0136 - val_mean_absolute_error: 0.0730 - val_binary_crossentropy: 0.3489\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0128 - mean_squared_error: 0.0122 - mean_absolute_error: 0.0702 - binary_crossentropy: 0.3499 - val_loss: 0.0142 - val_mean_squared_error: 0.0136 - val_mean_absolute_error: 0.0729 - val_binary_crossentropy: 0.3487\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0127 - mean_squared_error: 0.0121 - mean_absolute_error: 0.0699 - binary_crossentropy: 0.3492 - val_loss: 0.0141 - val_mean_squared_error: 0.0135 - val_mean_absolute_error: 0.0728 - val_binary_crossentropy: 0.3484\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0125 - mean_squared_error: 0.0119 - mean_absolute_error: 0.0696 - binary_crossentropy: 0.3486 - val_loss: 0.0141 - val_mean_squared_error: 0.0135 - val_mean_absolute_error: 0.0727 - val_binary_crossentropy: 0.3482\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0124 - mean_squared_error: 0.0118 - mean_absolute_error: 0.0694 - binary_crossentropy: 0.3481 - val_loss: 0.0140 - val_mean_squared_error: 0.0134 - val_mean_absolute_error: 0.0726 - val_binary_crossentropy: 0.3481\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0123 - mean_squared_error: 0.0117 - mean_absolute_error: 0.0691 - binary_crossentropy: 0.3476 - val_loss: 0.0140 - val_mean_squared_error: 0.0134 - val_mean_absolute_error: 0.0725 - val_binary_crossentropy: 0.3479\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0122 - mean_squared_error: 0.0116 - mean_absolute_error: 0.0688 - binary_crossentropy: 0.3470 - val_loss: 0.0139 - val_mean_squared_error: 0.0133 - val_mean_absolute_error: 0.0724 - val_binary_crossentropy: 0.3477\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0120 - mean_squared_error: 0.0115 - mean_absolute_error: 0.0686 - binary_crossentropy: 0.3465 - val_loss: 0.0139 - val_mean_squared_error: 0.0133 - val_mean_absolute_error: 0.0723 - val_binary_crossentropy: 0.3475\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0119 - mean_squared_error: 0.0114 - mean_absolute_error: 0.0683 - binary_crossentropy: 0.3461 - val_loss: 0.0138 - val_mean_squared_error: 0.0133 - val_mean_absolute_error: 0.0722 - val_binary_crossentropy: 0.3473\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0118 - mean_squared_error: 0.0113 - mean_absolute_error: 0.0681 - binary_crossentropy: 0.3457 - val_loss: 0.0138 - val_mean_squared_error: 0.0132 - val_mean_absolute_error: 0.0721 - val_binary_crossentropy: 0.3472\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0117 - mean_squared_error: 0.0112 - mean_absolute_error: 0.0678 - binary_crossentropy: 0.3453 - val_loss: 0.0137 - val_mean_squared_error: 0.0132 - val_mean_absolute_error: 0.0720 - val_binary_crossentropy: 0.3470\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0116 - mean_squared_error: 0.0111 - mean_absolute_error: 0.0676 - binary_crossentropy: 0.3448 - val_loss: 0.0137 - val_mean_squared_error: 0.0131 - val_mean_absolute_error: 0.0719 - val_binary_crossentropy: 0.3469\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0115 - mean_squared_error: 0.0110 - mean_absolute_error: 0.0673 - binary_crossentropy: 0.3443 - val_loss: 0.0136 - val_mean_squared_error: 0.0131 - val_mean_absolute_error: 0.0719 - val_binary_crossentropy: 0.3468\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0114 - mean_squared_error: 0.0109 - mean_absolute_error: 0.0671 - binary_crossentropy: 0.3439 - val_loss: 0.0136 - val_mean_squared_error: 0.0131 - val_mean_absolute_error: 0.0718 - val_binary_crossentropy: 0.3467\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0113 - mean_squared_error: 0.0108 - mean_absolute_error: 0.0669 - binary_crossentropy: 0.3435 - val_loss: 0.0135 - val_mean_squared_error: 0.0130 - val_mean_absolute_error: 0.0717 - val_binary_crossentropy: 0.3466\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0112 - mean_squared_error: 0.0107 - mean_absolute_error: 0.0667 - binary_crossentropy: 0.3431 - val_loss: 0.0135 - val_mean_squared_error: 0.0130 - val_mean_absolute_error: 0.0717 - val_binary_crossentropy: 0.3465\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0111 - mean_squared_error: 0.0106 - mean_absolute_error: 0.0665 - binary_crossentropy: 0.3426 - val_loss: 0.0135 - val_mean_squared_error: 0.0130 - val_mean_absolute_error: 0.0716 - val_binary_crossentropy: 0.3464\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0110 - mean_squared_error: 0.0105 - mean_absolute_error: 0.0663 - binary_crossentropy: 0.3422 - val_loss: 0.0134 - val_mean_squared_error: 0.0129 - val_mean_absolute_error: 0.0715 - val_binary_crossentropy: 0.3464\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0109 - mean_squared_error: 0.0104 - mean_absolute_error: 0.0661 - binary_crossentropy: 0.3418 - val_loss: 0.0134 - val_mean_squared_error: 0.0129 - val_mean_absolute_error: 0.0714 - val_binary_crossentropy: 0.3463\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0108 - mean_squared_error: 0.0103 - mean_absolute_error: 0.0659 - binary_crossentropy: 0.3414 - val_loss: 0.0134 - val_mean_squared_error: 0.0129 - val_mean_absolute_error: 0.0714 - val_binary_crossentropy: 0.3462\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0107 - mean_squared_error: 0.0102 - mean_absolute_error: 0.0657 - binary_crossentropy: 0.3411 - val_loss: 0.0133 - val_mean_squared_error: 0.0128 - val_mean_absolute_error: 0.0713 - val_binary_crossentropy: 0.3460\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0106 - mean_squared_error: 0.0102 - mean_absolute_error: 0.0655 - binary_crossentropy: 0.3407 - val_loss: 0.0133 - val_mean_squared_error: 0.0128 - val_mean_absolute_error: 0.0712 - val_binary_crossentropy: 0.3459\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0105 - mean_squared_error: 0.0101 - mean_absolute_error: 0.0653 - binary_crossentropy: 0.3404 - val_loss: 0.0132 - val_mean_squared_error: 0.0128 - val_mean_absolute_error: 0.0712 - val_binary_crossentropy: 0.3458\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0105 - mean_squared_error: 0.0100 - mean_absolute_error: 0.0652 - binary_crossentropy: 0.3401 - val_loss: 0.0132 - val_mean_squared_error: 0.0127 - val_mean_absolute_error: 0.0711 - val_binary_crossentropy: 0.3457\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0104 - mean_squared_error: 0.0099 - mean_absolute_error: 0.0650 - binary_crossentropy: 0.3397 - val_loss: 0.0132 - val_mean_squared_error: 0.0127 - val_mean_absolute_error: 0.0711 - val_binary_crossentropy: 0.3456\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0103 - mean_squared_error: 0.0099 - mean_absolute_error: 0.0648 - binary_crossentropy: 0.3394 - val_loss: 0.0131 - val_mean_squared_error: 0.0127 - val_mean_absolute_error: 0.0710 - val_binary_crossentropy: 0.3455\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0102 - mean_squared_error: 0.0098 - mean_absolute_error: 0.0646 - binary_crossentropy: 0.3391 - val_loss: 0.0131 - val_mean_squared_error: 0.0127 - val_mean_absolute_error: 0.0709 - val_binary_crossentropy: 0.3453\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0102 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0645 - binary_crossentropy: 0.3388 - val_loss: 0.0131 - val_mean_squared_error: 0.0126 - val_mean_absolute_error: 0.0709 - val_binary_crossentropy: 0.3452\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0101 - mean_squared_error: 0.0097 - mean_absolute_error: 0.0643 - binary_crossentropy: 0.3385 - val_loss: 0.0130 - val_mean_squared_error: 0.0126 - val_mean_absolute_error: 0.0708 - val_binary_crossentropy: 0.3451\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0100 - mean_squared_error: 0.0096 - mean_absolute_error: 0.0642 - binary_crossentropy: 0.3382 - val_loss: 0.0130 - val_mean_squared_error: 0.0126 - val_mean_absolute_error: 0.0707 - val_binary_crossentropy: 0.3450\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0100 - mean_squared_error: 0.0095 - mean_absolute_error: 0.0640 - binary_crossentropy: 0.3379 - val_loss: 0.0130 - val_mean_squared_error: 0.0126 - val_mean_absolute_error: 0.0706 - val_binary_crossentropy: 0.3449\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0099 - mean_squared_error: 0.0095 - mean_absolute_error: 0.0639 - binary_crossentropy: 0.3377 - val_loss: 0.0130 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0706 - val_binary_crossentropy: 0.3447\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0099 - mean_squared_error: 0.0094 - mean_absolute_error: 0.0637 - binary_crossentropy: 0.3374 - val_loss: 0.0129 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0705 - val_binary_crossentropy: 0.3445\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0098 - mean_squared_error: 0.0094 - mean_absolute_error: 0.0636 - binary_crossentropy: 0.3372 - val_loss: 0.0129 - val_mean_squared_error: 0.0125 - val_mean_absolute_error: 0.0704 - val_binary_crossentropy: 0.3444\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0097 - mean_squared_error: 0.0093 - mean_absolute_error: 0.0634 - binary_crossentropy: 0.3369 - val_loss: 0.0129 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0703 - val_binary_crossentropy: 0.3442\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0097 - mean_squared_error: 0.0093 - mean_absolute_error: 0.0633 - binary_crossentropy: 0.3367 - val_loss: 0.0128 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0702 - val_binary_crossentropy: 0.3440\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0096 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0631 - binary_crossentropy: 0.3364 - val_loss: 0.0128 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0702 - val_binary_crossentropy: 0.3439\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0096 - mean_squared_error: 0.0092 - mean_absolute_error: 0.0630 - binary_crossentropy: 0.3362 - val_loss: 0.0128 - val_mean_squared_error: 0.0124 - val_mean_absolute_error: 0.0701 - val_binary_crossentropy: 0.3437\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0095 - mean_squared_error: 0.0091 - mean_absolute_error: 0.0628 - binary_crossentropy: 0.3360 - val_loss: 0.0127 - val_mean_squared_error: 0.0123 - val_mean_absolute_error: 0.0700 - val_binary_crossentropy: 0.3436\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0095 - mean_squared_error: 0.0091 - mean_absolute_error: 0.0627 - binary_crossentropy: 0.3358 - val_loss: 0.0127 - val_mean_squared_error: 0.0123 - val_mean_absolute_error: 0.0699 - val_binary_crossentropy: 0.3434\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0094 - mean_squared_error: 0.0090 - mean_absolute_error: 0.0625 - binary_crossentropy: 0.3356 - val_loss: 0.0126 - val_mean_squared_error: 0.0123 - val_mean_absolute_error: 0.0698 - val_binary_crossentropy: 0.3432\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0094 - mean_squared_error: 0.0090 - mean_absolute_error: 0.0624 - binary_crossentropy: 0.3355 - val_loss: 0.0126 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0697 - val_binary_crossentropy: 0.3431\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0093 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0623 - binary_crossentropy: 0.3353 - val_loss: 0.0126 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0696 - val_binary_crossentropy: 0.3429\n"
     ]
    }
   ],
   "source": [
    "callbacks = ([\n",
    "    MacKayRegularization(data_est_std),\n",
    "    CalcLogMSE(),\n",
    "    ReduceLROnPlateau(monitor='log_mse', epsilon=0.01, min_lr=1e-7, patience=6),\n",
    "    ModelCheckpoint(model_checkpoint_filepath, monitor='val_loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    TerminateOnNaN(),\n",
    "])\n",
    "hists.append(model.fit_generator(gen_train, verbose=2, steps_per_epoch=steps_per_epoch, epochs=max_epochs,\n",
    "                                 callbacks=callbacks,\n",
    "                                 max_queue_size=500, workers=1, validation_data=validation_data).history)\n",
    "jhists = join_hists(hists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High Parameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = model.get_weights()\n",
    "w, b = pauli_to_arb_weights(w,b,hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl1 = K.get_value(model.layers[0].regularizer_k.l1)\n",
    "bl1 = K.get_value(model.layers[0].regularizer_b.l1)\n",
    "lr = K.get_value(model.optimizer.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(StateProbabilities(nqubits=n, ndrives=nb_drives,\n",
    "                              l1_lambda=2e-3))\n",
    "model1.compile(loss='mse', optimizer=Adam(lr=1e-4), metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "K.set_value(model1.layers[0].regularizer_k.l1, kl1)\n",
    "K.set_value(model1.layers[0].regularizer_b.l1, bl1)\n",
    "#K.set_value(model1.optimizer.lr, lr)\n",
    "model1.set_weights((w,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 0s - loss: 0.0099 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0621 - binary_crossentropy: 0.3352 - val_loss: 0.0132 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0695 - val_binary_crossentropy: 0.3429\n",
      "Epoch 2/50\n",
      " - 0s - loss: 0.0099 - mean_squared_error: 0.0089 - mean_absolute_error: 0.0620 - binary_crossentropy: 0.3350 - val_loss: 0.0132 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0695 - val_binary_crossentropy: 0.3428\n",
      "Epoch 3/50\n",
      " - 0s - loss: 0.0098 - mean_squared_error: 0.0088 - mean_absolute_error: 0.0619 - binary_crossentropy: 0.3349 - val_loss: 0.0132 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0695 - val_binary_crossentropy: 0.3428\n",
      "Epoch 4/50\n",
      " - 0s - loss: 0.0098 - mean_squared_error: 0.0088 - mean_absolute_error: 0.0618 - binary_crossentropy: 0.3348 - val_loss: 0.0132 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0695 - val_binary_crossentropy: 0.3427\n",
      "Epoch 5/50\n",
      " - 0s - loss: 0.0098 - mean_squared_error: 0.0088 - mean_absolute_error: 0.0618 - binary_crossentropy: 0.3347 - val_loss: 0.0131 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0694 - val_binary_crossentropy: 0.3427\n",
      "Epoch 6/50\n",
      " - 0s - loss: 0.0097 - mean_squared_error: 0.0088 - mean_absolute_error: 0.0617 - binary_crossentropy: 0.3346 - val_loss: 0.0131 - val_mean_squared_error: 0.0122 - val_mean_absolute_error: 0.0694 - val_binary_crossentropy: 0.3427\n",
      "Epoch 7/50\n",
      " - 0s - loss: 0.0097 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0616 - binary_crossentropy: 0.3345 - val_loss: 0.0131 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0694 - val_binary_crossentropy: 0.3426\n",
      "Epoch 8/50\n",
      " - 0s - loss: 0.0097 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0615 - binary_crossentropy: 0.3344 - val_loss: 0.0131 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0693 - val_binary_crossentropy: 0.3426\n",
      "Epoch 9/50\n",
      " - 0s - loss: 0.0096 - mean_squared_error: 0.0087 - mean_absolute_error: 0.0614 - binary_crossentropy: 0.3342 - val_loss: 0.0131 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0693 - val_binary_crossentropy: 0.3425\n",
      "Epoch 10/50\n",
      " - 0s - loss: 0.0096 - mean_squared_error: 0.0086 - mean_absolute_error: 0.0613 - binary_crossentropy: 0.3341 - val_loss: 0.0131 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0693 - val_binary_crossentropy: 0.3425\n",
      "Epoch 11/50\n",
      " - 0s - loss: 0.0095 - mean_squared_error: 0.0086 - mean_absolute_error: 0.0612 - binary_crossentropy: 0.3340 - val_loss: 0.0130 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0693 - val_binary_crossentropy: 0.3425\n",
      "Epoch 12/50\n",
      " - 0s - loss: 0.0095 - mean_squared_error: 0.0086 - mean_absolute_error: 0.0611 - binary_crossentropy: 0.3339 - val_loss: 0.0130 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0692 - val_binary_crossentropy: 0.3424\n",
      "Epoch 13/50\n",
      " - 0s - loss: 0.0095 - mean_squared_error: 0.0086 - mean_absolute_error: 0.0610 - binary_crossentropy: 0.3338 - val_loss: 0.0130 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0692 - val_binary_crossentropy: 0.3424\n",
      "Epoch 14/50\n",
      " - 0s - loss: 0.0094 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0609 - binary_crossentropy: 0.3337 - val_loss: 0.0130 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0692 - val_binary_crossentropy: 0.3423\n",
      "Epoch 15/50\n",
      " - 0s - loss: 0.0094 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0609 - binary_crossentropy: 0.3336 - val_loss: 0.0130 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0692 - val_binary_crossentropy: 0.3423\n",
      "Epoch 16/50\n",
      " - 0s - loss: 0.0094 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0608 - binary_crossentropy: 0.3335 - val_loss: 0.0130 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0691 - val_binary_crossentropy: 0.3423\n",
      "Epoch 17/50\n",
      " - 0s - loss: 0.0093 - mean_squared_error: 0.0085 - mean_absolute_error: 0.0607 - binary_crossentropy: 0.3334 - val_loss: 0.0130 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0691 - val_binary_crossentropy: 0.3423\n",
      "Epoch 18/50\n",
      " - 0s - loss: 0.0093 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0606 - binary_crossentropy: 0.3333 - val_loss: 0.0129 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0691 - val_binary_crossentropy: 0.3422\n",
      "Epoch 19/50\n",
      " - 0s - loss: 0.0093 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0605 - binary_crossentropy: 0.3332 - val_loss: 0.0129 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0690 - val_binary_crossentropy: 0.3422\n",
      "Epoch 20/50\n",
      " - 0s - loss: 0.0092 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0604 - binary_crossentropy: 0.3332 - val_loss: 0.0129 - val_mean_squared_error: 0.0121 - val_mean_absolute_error: 0.0690 - val_binary_crossentropy: 0.3422\n",
      "Epoch 21/50\n",
      " - 0s - loss: 0.0092 - mean_squared_error: 0.0084 - mean_absolute_error: 0.0603 - binary_crossentropy: 0.3331 - val_loss: 0.0129 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0690 - val_binary_crossentropy: 0.3421\n",
      "Epoch 22/50\n",
      " - 0s - loss: 0.0092 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0603 - binary_crossentropy: 0.3330 - val_loss: 0.0129 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0690 - val_binary_crossentropy: 0.3420\n",
      "Epoch 23/50\n",
      " - 0s - loss: 0.0091 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0602 - binary_crossentropy: 0.3329 - val_loss: 0.0129 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0689 - val_binary_crossentropy: 0.3420\n",
      "Epoch 24/50\n",
      " - 0s - loss: 0.0091 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0601 - binary_crossentropy: 0.3328 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0689 - val_binary_crossentropy: 0.3419\n",
      "Epoch 25/50\n",
      " - 0s - loss: 0.0091 - mean_squared_error: 0.0083 - mean_absolute_error: 0.0600 - binary_crossentropy: 0.3327 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0689 - val_binary_crossentropy: 0.3419\n",
      "Epoch 26/50\n",
      " - 0s - loss: 0.0090 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0599 - binary_crossentropy: 0.3326 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0689 - val_binary_crossentropy: 0.3418\n",
      "Epoch 27/50\n",
      " - 0s - loss: 0.0090 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0598 - binary_crossentropy: 0.3325 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0688 - val_binary_crossentropy: 0.3418\n",
      "Epoch 28/50\n",
      " - 0s - loss: 0.0090 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0598 - binary_crossentropy: 0.3324 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0688 - val_binary_crossentropy: 0.3417\n",
      "Epoch 29/50\n",
      " - 0s - loss: 0.0089 - mean_squared_error: 0.0082 - mean_absolute_error: 0.0597 - binary_crossentropy: 0.3323 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0688 - val_binary_crossentropy: 0.3417\n",
      "Epoch 30/50\n",
      " - 0s - loss: 0.0089 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0596 - binary_crossentropy: 0.3322 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0688 - val_binary_crossentropy: 0.3416\n",
      "Epoch 31/50\n",
      " - 0s - loss: 0.0089 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0595 - binary_crossentropy: 0.3321 - val_loss: 0.0128 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0688 - val_binary_crossentropy: 0.3416\n",
      "Epoch 32/50\n",
      " - 0s - loss: 0.0089 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0594 - binary_crossentropy: 0.3320 - val_loss: 0.0127 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0687 - val_binary_crossentropy: 0.3416\n",
      "Epoch 33/50\n",
      " - 0s - loss: 0.0088 - mean_squared_error: 0.0081 - mean_absolute_error: 0.0594 - binary_crossentropy: 0.3319 - val_loss: 0.0127 - val_mean_squared_error: 0.0120 - val_mean_absolute_error: 0.0687 - val_binary_crossentropy: 0.3415\n",
      "Epoch 34/50\n",
      " - 0s - loss: 0.0088 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0593 - binary_crossentropy: 0.3319 - val_loss: 0.0127 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0687 - val_binary_crossentropy: 0.3415\n",
      "Epoch 35/50\n",
      " - 0s - loss: 0.0088 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0592 - binary_crossentropy: 0.3318 - val_loss: 0.0127 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0687 - val_binary_crossentropy: 0.3414\n",
      "Epoch 36/50\n",
      " - 0s - loss: 0.0087 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0591 - binary_crossentropy: 0.3317 - val_loss: 0.0127 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0686 - val_binary_crossentropy: 0.3414\n",
      "Epoch 37/50\n",
      " - 0s - loss: 0.0087 - mean_squared_error: 0.0080 - mean_absolute_error: 0.0590 - binary_crossentropy: 0.3316 - val_loss: 0.0127 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0686 - val_binary_crossentropy: 0.3414\n",
      "Epoch 38/50\n",
      " - 0s - loss: 0.0087 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0590 - binary_crossentropy: 0.3315 - val_loss: 0.0127 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0686 - val_binary_crossentropy: 0.3413\n",
      "Epoch 39/50\n",
      " - 0s - loss: 0.0087 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0589 - binary_crossentropy: 0.3314 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0686 - val_binary_crossentropy: 0.3413\n",
      "Epoch 40/50\n",
      " - 0s - loss: 0.0086 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0588 - binary_crossentropy: 0.3314 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0685 - val_binary_crossentropy: 0.3413\n",
      "Epoch 41/50\n",
      " - 0s - loss: 0.0086 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0587 - binary_crossentropy: 0.3313 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0685 - val_binary_crossentropy: 0.3412\n",
      "Epoch 42/50\n",
      " - 0s - loss: 0.0086 - mean_squared_error: 0.0079 - mean_absolute_error: 0.0586 - binary_crossentropy: 0.3312 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0685 - val_binary_crossentropy: 0.3412\n",
      "Epoch 43/50\n",
      " - 0s - loss: 0.0085 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0586 - binary_crossentropy: 0.3311 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0685 - val_binary_crossentropy: 0.3412\n",
      "Epoch 44/50\n",
      " - 0s - loss: 0.0085 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0585 - binary_crossentropy: 0.3310 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0685 - val_binary_crossentropy: 0.3411\n",
      "Epoch 45/50\n",
      " - 0s - loss: 0.0085 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0584 - binary_crossentropy: 0.3310 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0684 - val_binary_crossentropy: 0.3411\n",
      "Epoch 46/50\n",
      " - 0s - loss: 0.0085 - mean_squared_error: 0.0078 - mean_absolute_error: 0.0583 - binary_crossentropy: 0.3309 - val_loss: 0.0126 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0684 - val_binary_crossentropy: 0.3411\n",
      "Epoch 47/50\n",
      " - 0s - loss: 0.0084 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0583 - binary_crossentropy: 0.3308 - val_loss: 0.0125 - val_mean_squared_error: 0.0119 - val_mean_absolute_error: 0.0684 - val_binary_crossentropy: 0.3410\n",
      "Epoch 48/50\n",
      " - 0s - loss: 0.0084 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0582 - binary_crossentropy: 0.3307 - val_loss: 0.0125 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0684 - val_binary_crossentropy: 0.3410\n",
      "Epoch 49/50\n",
      " - 0s - loss: 0.0084 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0581 - binary_crossentropy: 0.3307 - val_loss: 0.0125 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0683 - val_binary_crossentropy: 0.3410\n",
      "Epoch 50/50\n",
      " - 0s - loss: 0.0084 - mean_squared_error: 0.0077 - mean_absolute_error: 0.0580 - binary_crossentropy: 0.3306 - val_loss: 0.0125 - val_mean_squared_error: 0.0118 - val_mean_absolute_error: 0.0683 - val_binary_crossentropy: 0.3409\n"
     ]
    }
   ],
   "source": [
    "callbacks = ([\n",
    "    MacKayRegularization(data_est_std),\n",
    "    CalcLogMSE(),\n",
    "    ReduceLROnPlateau(monitor='log_mse', epsilon=0.01, min_lr=1e-7, patience=6),\n",
    "    ModelCheckpoint(model1_checkpoint_filepath, monitor='val_loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    TerminateOnNaN(),\n",
    "])\n",
    "hists1.append(model1.fit_generator(gen_train, verbose=2, steps_per_epoch=steps_per_epoch, epochs=max_epochs,\n",
    "                                   callbacks=callbacks,\n",
    "                                   max_queue_size=500, workers=1, validation_data=validation_data).history)\n",
    "jhists1 = join_hists(hists1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time dependent\n",
    "\n",
    "Use `StateProbabilitiesTimeDep`.\n",
    "\n",
    "See section \"Validation checks\" for usage examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time dependent non-unitary\n",
    "\n",
    "Use `StateProbabilitiesTimeDepLindblad` (or `StateProbabilitiesTimeDepLindbladRK4` for higher precision).\n",
    "\n",
    "See section \"Validation checks\" for usage examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation checks\n",
    "\n",
    "Reimplementing everything in a few different ways to ensure that the numerics work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unitary checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "# Testing different parameterizations\n",
      "#\n",
      "difference in low and high H:  6.915692425668235e-16\n",
      "#\n",
      "# Testing NUMPY models\n",
      "#\n",
      "prop_pade {}\n",
      "    [0.961 0.003 0.03...] Sum-1: 4.441e-16 Pade diff: 0.000e+00\n",
      "prop_eig {}\n",
      "    [0.961 0.003 0.03...] Sum-1: 6.661e-16 Pade diff: 2.690e-16\n",
      "prop_euler {'N': 100}\n",
      "    [9.612e-01 9.041e-04 3.450e-0...] Sum-1: 4.180e-04 Pade diff: 9.727e-03\n",
      "prop_taylor {'order': 5}\n",
      "    [0.961 0.003 0.03...] Sum-1: 2.053e-06 Pade diff: 2.982e-06\n",
      "prop_taylor {'order': 15}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1.110e-16 Pade diff: 4.546e-16\n",
      "prop_taylor {'order': 25}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1.110e-16 Pade diff: 4.546e-16\n",
      "prop_eulertaylor {'N': 100, 'order': 3}\n",
      "    [0.961 0.003 0.03...] Sum-1: -3.746e-10 Pade diff: 4.388e-10\n",
      "prop_eulereig {'N': 100}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1.954e-14 Pade diff: 2.004e-14\n",
      "#\n",
      "# Testing TENSORFLOW models\n",
      "#\n",
      "prop_model_low {}\n",
      "    [0.961 0.003 0.03...] Sum-1: -2e-15 Pade diff: 1.902e-15\n",
      "prop_model_high {}\n",
      "    [0.961 0.003 0.03...] Sum-1: -6e-16 Pade diff: 9.586e-16\n",
      "prop_model_highT {'timesteps': 100, 'taylorord': 1, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: 4e-04 Pade diff: 4.524e-04\n",
      "prop_model_highT {'timesteps': 100, 'taylorord': 3, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: -4e-10 Pade diff: 4.388e-10\n",
      "prop_model_highT {'timesteps': 100, 'taylorord': 10, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: 1e-15 Pade diff: 8.913e-16\n",
      "prop_model_highT {'timesteps': 100, 'taylorord': 'eig', 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1e-14 Pade diff: 1.476e-14\n",
      "prop_model_highT {'timesteps': 1000, 'taylorord': 1, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: 4e-05 Pade diff: 4.521e-05\n",
      "prop_model_highT {'timesteps': 1000, 'taylorord': 3, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: -4e-13 Pade diff: 4.383e-13\n",
      "prop_model_highT {'timesteps': 1000, 'taylorord': 10, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1e-15 Pade diff: 1.605e-15\n",
      "prop_model_highT {'timesteps': 1000, 'taylorord': 'eig', 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1e-13 Pade diff: 1.476e-13\n",
      "prop_model_highT {'timesteps': 100, 'taylorord': 3, 'normalize': True}\n",
      "WARNING:tensorflow:From /gpfs/loomis/home.grace/fas/jiang/sk943/hamiltonian_estimation/4.initializer_ladder/hamest.py:221: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /gpfs/loomis/home.grace/fas/jiang/sk943/hamiltonian_estimation/4.initializer_ladder/hamest.py:221: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    [0.961 0.003 0.03...] Sum-1: 2e-16 Pade diff: 1.164e-10\n",
      "prop_model_highT {'timesteps': 1000, 'taylorord': 3, 'normalize': True}\n",
      "    [0.961 0.003 0.03...] Sum-1: 0e+00 Pade diff: 1.185e-13\n",
      "prop_model_highTLindblad {'timesteps': 1000, 'hermify': False, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: 4e-16 Pade diff: 7.043e-05\n",
      "prop_model_highTLindblad {'timesteps': 1000, 'hermify': False, 'normalize': True}\n",
      "    [0.961 0.003 0.03...] Sum-1: 0e+00 Pade diff: 7.043e-05\n",
      "prop_model_highTLindblad {'timesteps': 1000, 'hermify': True, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: 4e-16 Pade diff: 7.043e-05\n",
      "prop_model_highTLindblad {'timesteps': 1000, 'hermify': True, 'normalize': True}\n",
      "    [0.961 0.003 0.03...] Sum-1: 0e+00 Pade diff: 7.043e-05\n",
      "prop_model_highTLindblad {'timesteps': 10000, 'hermify': False, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: -4e-15 Pade diff: 7.042e-06\n",
      "prop_model_highTLindbladRK4 {'timesteps': 10, 'hermify': False, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: 0e+00 Pade diff: 2.818e-08\n",
      "prop_model_highTLindbladRK4 {'timesteps': 10, 'hermify': False, 'normalize': True}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1e-16 Pade diff: 2.818e-08\n",
      "prop_model_highTLindbladRK4 {'timesteps': 10, 'hermify': True, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: 0e+00 Pade diff: 2.818e-08\n",
      "prop_model_highTLindbladRK4 {'timesteps': 10, 'hermify': True, 'normalize': True}\n",
      "    [0.961 0.003 0.03...] Sum-1: -1e-16 Pade diff: 2.818e-08\n",
      "prop_model_highTLindbladRK4 {'timesteps': 100, 'hermify': False, 'normalize': False}\n",
      "    [0.961 0.003 0.03...] Sum-1: -2e-16 Pade diff: 2.798e-12\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(StateProbabilitiesPaulied(nqubits=n, ndrives=nb_drives, paulies=hs,\n",
    "                                    l1_lambda=2e-3))\n",
    "model.compile(loss='mse', optimizer=Adam(lr=1e-3), metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "w=model.get_weights()\n",
    "x = next(gen_train)[0][:1]\n",
    "\n",
    "np.set_printoptions(precision=3, linewidth=90)\n",
    "\n",
    "def repeat(x, timesteps):\n",
    "    x_rep = np.vstack([np.squeeze(x)]*timesteps)\n",
    "    x_rep.shape = 1, *x_rep.shape\n",
    "    return x_rep\n",
    "\n",
    "def init(size):\n",
    "    s = np.zeros(size)\n",
    "    s[0] = 1\n",
    "    return s\n",
    "\n",
    "def low_to_H(ws, d, hs):\n",
    "    w, b = ws\n",
    "    return np.tensordot(hs, w.T.dot(d)+b, [[0],[0]])\n",
    "\n",
    "def high_to_H(ws, d):\n",
    "    w, b = ws\n",
    "    size = int(np.sqrt(b.shape[0])+0.01)\n",
    "    M = np.reshape(w.T.dot(d)+b, (size,size))\n",
    "    return (M+M.T)+1j*(M-M.T)\n",
    "\n",
    "def prop_model_low(nqubits, ndrives, w, x, hs):\n",
    "    stateprob = StateProbabilitiesPaulied(nqubits=nqubits, ndrives=ndrives,\n",
    "                                          paulies=hs,\n",
    "                                          l1_lambda=2e-3)\n",
    "    model = Sequential()\n",
    "    model.add(stateprob)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4),\n",
    "                  metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "    model.set_weights(w)\n",
    "    return model.predict(x)[0]\n",
    "\n",
    "def prop_model_high(nqubits, ndrives, w, x, hs):\n",
    "    stateprob = StateProbabilities(nqubits=nqubits, ndrives=ndrives,\n",
    "                                   l1_lambda=2e-3)\n",
    "    model = Sequential()\n",
    "    model.add(stateprob)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4),\n",
    "                  metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "    model.set_weights(pauli_to_arb_weights(*w,hs))\n",
    "    return model.predict(x)[0]\n",
    "\n",
    "def prop_model_highT(nqubits, ndrives, w, x, hs, timesteps=100, taylorord=3, normalize=False):\n",
    "    stateprob = StateProbabilities(nqubits=nqubits, ndrives=ndrives,\n",
    "                                   l1_lambda=2e-3)\n",
    "    stateprobT = StateProbabilitiesTimeDep(timesteps=timesteps, baseham=stateprob,\n",
    "                                           normalize=normalize, taylorord=taylorord)\n",
    "    model = Sequential()\n",
    "    model.add(stateprobT)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4),\n",
    "                  metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "    model.set_weights(pauli_to_arb_weights(*w,hs))\n",
    "    return model.predict(repeat(x, timesteps))[0]\n",
    "\n",
    "def prop_model_highTLindblad(nqubits, ndrives, w, x, hs, timesteps=100, normalize=False, hermify=False):\n",
    "    stateprob = StateProbabilities(nqubits=nqubits, ndrives=ndrives,\n",
    "                                   l1_lambda=2e-3)\n",
    "    stateprobT = StateProbabilitiesTimeDepLindblad(\n",
    "        timesteps=timesteps, baseham=stateprob,\n",
    "        normalize=normalize, hermify=hermify)\n",
    "    model = Sequential()\n",
    "    model.add(stateprobT)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4),\n",
    "                  metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "    model.set_weights(pauli_to_arb_weights(*w,hs))\n",
    "    return model.predict(repeat(x, timesteps))[0]\n",
    "\n",
    "def prop_model_highTLindbladRK4(nqubits, ndrives, w, x, hs, timesteps=100, normalize=False, hermify=False):\n",
    "    stateprob = StateProbabilities(nqubits=nqubits, ndrives=ndrives,\n",
    "                                   l1_lambda=2e-3)\n",
    "    stateprobT = StateProbabilitiesTimeDepLindbladRK4(\n",
    "        timesteps=timesteps, baseham=stateprob,\n",
    "        normalize=normalize, hermify=hermify)\n",
    "    model = Sequential()\n",
    "    model.add(stateprobT)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4),\n",
    "                  metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "    model.set_weights(pauli_to_arb_weights(*w,hs))\n",
    "    return model.predict(repeat(x, timesteps))[0]\n",
    "\n",
    "def prop_taylor(h, state, order=3):\n",
    "    '''Taylor exp: sum (-ih)**j/j! for j in 0..order'''\n",
    "    out = state\n",
    "    for i in range(order,0,-1):\n",
    "        out = state-1j/i*np.dot(h,out)\n",
    "    return out\n",
    "\n",
    "def prop_euler(h, state, N=10):\n",
    "    '''Euler method: (1-ih/N)**N'''\n",
    "    hNp1 = np.eye(len(h))+1j*h/N\n",
    "    for _ in range(N):\n",
    "        state = hNp1.dot(state)\n",
    "    return state\n",
    "\n",
    "def prop_eulertaylor(h, state, order=3, N=10):\n",
    "    '''Euler+Taylor: (sum (-ih/N)**j/j! for j in 0..order)**N'''\n",
    "    for _ in range(N):\n",
    "        state = prop_taylor(h/N, state, order=order)\n",
    "    return state\n",
    "\n",
    "def prop_eulereig(h, state, N=10):\n",
    "    '''Euler+Eig: exp(-ih/N)**N'''\n",
    "    for _ in range(N):\n",
    "        state = prop_eig(h/N, state)\n",
    "    return state\n",
    "\n",
    "def prop_pade(h, state):\n",
    "    '''Pade approximation of exp(-ih)'''\n",
    "    return scipy.linalg.expm(-1j*h).dot(state)\n",
    "\n",
    "def prop_eig(h, state):\n",
    "    '''Eigendecomposition for exp'''\n",
    "    e,v = np.linalg.eigh(h)\n",
    "    pre = np.conj(v.T)\n",
    "    post = v\n",
    "    return post.dot(np.exp(-1j*e)*pre.dot(state))\n",
    "\n",
    "amp_to_prob = lambda _:np.abs(_)**2\n",
    "f_args = [\n",
    "    (prop_pade, {}),\n",
    "    (prop_eig, {}),\n",
    "    (prop_euler, dict(N=100)),\n",
    "    (prop_taylor, dict(order=5)),\n",
    "    (prop_taylor, dict(order=15)),\n",
    "    (prop_taylor, dict(order=25)),\n",
    "    (prop_eulertaylor, dict(N=100, order=3)),\n",
    "    (prop_eulereig, dict(N=100)),\n",
    "]\n",
    "f_args_models = [\n",
    "    (prop_model_low, {}),\n",
    "    (prop_model_high, {}),\n",
    "    (prop_model_highT, dict(timesteps=100, taylorord=1, normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=100, taylorord=3, normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=100, taylorord=10, normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=100, taylorord='eig', normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=1000, taylorord=1, normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=1000, taylorord=3, normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=1000, taylorord=10, normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=1000, taylorord='eig', normalize=False)),\n",
    "    (prop_model_highT, dict(timesteps=100, taylorord=3, normalize=True)),\n",
    "    (prop_model_highT, dict(timesteps=1000, taylorord=3, normalize=True)),\n",
    "    (prop_model_highTLindblad, dict(timesteps=1000, hermify=False, normalize=False)),\n",
    "    (prop_model_highTLindblad, dict(timesteps=1000, hermify=False, normalize=True)),\n",
    "    (prop_model_highTLindblad, dict(timesteps=1000, hermify=True, normalize=False)),\n",
    "    (prop_model_highTLindblad, dict(timesteps=1000, hermify=True, normalize=True)),\n",
    "    (prop_model_highTLindblad, dict(timesteps=10000, hermify=False, normalize=False)),\n",
    "    (prop_model_highTLindbladRK4, dict(timesteps=10, hermify=False, normalize=False)),\n",
    "    (prop_model_highTLindbladRK4, dict(timesteps=10, hermify=False, normalize=True)),\n",
    "    (prop_model_highTLindbladRK4, dict(timesteps=10, hermify=True, normalize=False)),\n",
    "    (prop_model_highTLindbladRK4, dict(timesteps=10, hermify=True, normalize=True)),\n",
    "    (prop_model_highTLindbladRK4, dict(timesteps=100, hermify=False, normalize=False)),\n",
    "]\n",
    "i = init(2**n)\n",
    "low = low_to_H(w, x[0], hs)\n",
    "high = high_to_H(pauli_to_arb_weights(*w,hs), x[0])\n",
    "print('#')\n",
    "print('# Testing different parameterizations')\n",
    "print('#')\n",
    "print('difference in low and high H: ', np.sum(np.abs(high-low)))\n",
    "print('#')\n",
    "print('# Testing NUMPY models')\n",
    "print('#')\n",
    "pade_amp = prop_pade(low, i)\n",
    "pade_prob = np.abs(pade_amp)**2\n",
    "for f,args in f_args:\n",
    "    print(f.__name__,args)\n",
    "    amp = f(low, i, **args)\n",
    "    prob = amp_to_prob(amp)\n",
    "    print('    %s...] '%str(prob[:3])[:-2], end='')\n",
    "    print('Sum-1: %.3e'%(np.sum(prob)-1), 'Pade diff: %.3e'%np.sum(np.abs(prob-pade_prob)))\n",
    "print('#')\n",
    "print('# Testing TENSORFLOW models')\n",
    "print('#')\n",
    "for f,args in f_args_models:\n",
    "    print(f.__name__, args)\n",
    "    prob = f(n, nb_drives, w, x, hs, **args)\n",
    "    print('    %s...] '%str(prob[:3])[:-2], end='')\n",
    "    print('Sum-1: %.e'%(np.sum(prob)-1), 'Pade diff: %.3e'%np.sum(np.abs(prob-pade_prob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-unitary checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qutip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = low\n",
    "i = qutip.identity(2).full()\n",
    "s = qutip.sigmam().full()\n",
    "k = lambda a,b,c: np.kron(a,np.kron(b,c))\n",
    "ls = k(s,i,i)*0.1,k(i,s,i)*0.2,k(i,i,s)*0.3 \n",
    "state = np.array([1]+[0]*(h.shape[0]-1))\n",
    "\n",
    "def propNU_qutip_mesolve(h,ls,state):\n",
    "    n = h.shape[0]\n",
    "    h = qutip.Qobj(h)\n",
    "    ls = [qutip.Qobj(_) for _ in ls]\n",
    "    r = qutip.mesolve(h,qutip.Qobj(state),np.linspace(0,1,1000),c_ops=ls)\n",
    "    return np.abs(r.states[-1].full().diagonal()) \n",
    "\n",
    "def propNU_model_highTLindblad(nqubits, ndrives, w, x, hs, ls, timesteps=100, normalize=False, hermify=False):\n",
    "    stateprob = StateProbabilities(nqubits=nqubits, ndrives=ndrives,\n",
    "                                   l1_lambda=2e-3)\n",
    "    stateprobT = StateProbabilitiesTimeDepLindblad(\n",
    "        timesteps=timesteps, baseham=stateprob,\n",
    "        lindblads=ls,\n",
    "        normalize=normalize, hermify=hermify)\n",
    "    model = Sequential()\n",
    "    model.add(stateprobT)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4),\n",
    "                  metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "    model.set_weights([*pauli_to_arb_weights(*w,hs),np.array([1,1,1])])\n",
    "    return model.predict(repeat(x, timesteps))[0]\n",
    "\n",
    "def propNU_model_highTLindbladRK4(nqubits, ndrives, w, x, hs, ls, timesteps=100, normalize=False, hermify=False):\n",
    "    stateprob = StateProbabilities(nqubits=nqubits, ndrives=ndrives,\n",
    "                                   l1_lambda=2e-3)\n",
    "    stateprobT = StateProbabilitiesTimeDepLindbladRK4(\n",
    "        timesteps=timesteps, baseham=stateprob,\n",
    "        lindblads=ls,\n",
    "        normalize=normalize, hermify=hermify)\n",
    "    model = Sequential()\n",
    "    model.add(stateprobT)\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=1e-4),\n",
    "                  metrics=['mse', 'mae', 'binary_crossentropy'])\n",
    "    model.set_weights([*pauli_to_arb_weights(*w,hs),np.array([1,1,1])])\n",
    "    return model.predict(repeat(x, timesteps))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qt = propNU_qutip_mesolve(h,ls,state)\n",
    "sum(qt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = propNU_model_highTLindblad(n, nb_drives, w, x, hs, np.array(ls), timesteps=100, hermify=False, normalize=False)\n",
    "sum(lb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbrk = propNU_model_highTLindbladRK4(n, nb_drives, w, x, hs, np.array(ls), timesteps=100, hermify=False, normalize=False)\n",
    "sum(lbrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005491377049087166"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(qt-lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.081380278575183e-08"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(qt-lbrk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.084694428083395e-08"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbrk = propNU_model_highTLindbladRK4(n, nb_drives, w, x, hs, np.array(ls), timesteps=50, hermify=False, normalize=False)\n",
    "np.sum(np.abs(qt-lbrk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0544385381283444e-07"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbrk = propNU_model_highTLindbladRK4(n, nb_drives, w, x, hs, np.array(ls), timesteps=10, hermify=False, normalize=False)\n",
    "np.sum(np.abs(qt-lbrk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.931738377163836e-07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbrk = propNU_model_highTLindbladRK4(n, nb_drives, w, x, hs, np.array(ls), timesteps=5, hermify=False, normalize=False)\n",
    "np.sum(np.abs(qt-lbrk))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
